# -*- coding: utf-8 -*-
"""License_plate_recognition_nvidianet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ggAQgFMbdc8RfOi4vtMp6k47bAQbptjl
"""

import tensorflow as tf


import warnings
warnings.filterwarnings('ignore')

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import cv2
import numpy as np
import glob
from keras.preprocessing.image import ImageDataGenerator, load_img
# %matplotlib inline

image_gen = ImageDataGenerator(rotation_range=10,
                              width_shift_range=0.2,
                              height_shift_range=0.2,
                              rescale=1/255,
                              fill_mode="nearest",
                              validation_split=0.1) # set validation split

print(image_gen.flow_from_directory("/content/drive/MyDrive/test data/test_data"))

import tensorflow as tf
import keras
from keras.models import Sequential 
from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, AveragePooling2D
from keras.optimizers import Adam
from keras.models import load_model
from keras.callbacks import ModelCheckpoint, EarlyStopping

def nvidia_model():
    model = Sequential(name='Nvidia_Model2')
    
    # elu=Expenential Linear Unit, similar to leaky Relu
    # skipping 1st hiddel layer (nomralization layer), as we have normalized the data
    
    # Convolution Layers
    model.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=(224, 80, 3), activation='elu')) 
    model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu')) 
    model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu')) 
    model.add(Conv2D(64, (3, 3), activation='elu')) 
    model.add(Dropout(0.2)) # not in original model. added for more robustness
    model.add(Conv2D(64, (3, 3), activation='elu'))
    
    # Fully Connected Layers
    model.add(Flatten())
    model.add(Dropout(0.2)) # not in original model. added for more robustness
    model.add(Dense(100, activation='elu'))
    model.add(Dense(50, activation='elu'))
    model.add(Dense(10, activation='elu'))
      
    # output layer:
    model.add(Dense(512, activation='elu'))  # not in original model. added for more robustness
    model.add(Dense(11,activation='softmax'))
    
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

model = nvidia_model()
print(model.summary())

checkpoint_filepath = 'License_plate_nvidia.h5'
# EarlyStopping allows model to stop traning in case loss is not reduced after 5 epochs 
# ModelCheckpoint allosw model to save weight everytime loss is reduced
my_checkpointer = [
                   EarlyStopping(monitor='val_loss', patience=5, verbose=0),
                   ModelCheckpoint(filepath=checkpoint_filepath, verbose=1, save_best_only=True)
                   ]

input_shape = (224,80,3)
batch_size = 150

train_image_gen = image_gen.flow_from_directory("/content/drive/MyDrive/test data/test_data",
                                                target_size=input_shape[:2],
                                                batch_size=batch_size,
                                                class_mode="categorical",
                                                subset="training")
valid_image_gen = image_gen.flow_from_directory("/content/drive/MyDrive/test data/test_data",
                                                target_size=input_shape[:2],
                                                batch_size=batch_size,
                                                class_mode="categorical",
                                                subset="validation")

#model.load_weights("License_plate_nvidia.h5")
result = model.fit_generator(train_image_gen,epochs=40,steps_per_epoch=len(train_image_gen),
                           validation_data=valid_image_gen,validation_steps=len(valid_image_gen),callbacks=my_checkpointer,verbose=1)

import matplotlib.pyplot as plt
plt.figure(0)
plt.plot(result.history['accuracy'], label='training accuracy')
plt.plot(result.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
#plt.savefig("Accuracy.png", dpi=300)

plt.figure(1)
plt.plot(result.history['loss'], label='training loss')
plt.plot(result.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()

plt.savefig("Loss.png", dpi=300)

from keras.models import model_from_json
model_json = model.to_json()
with open("License_plate_nvidia.json","w") as json_file:
  json_file.write(model_json)





















adam = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, amsgrad=False)
model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])
result2 = model.fit_generator(train_image_gen,epochs=40,steps_per_epoch=len(train_image_gen),
                           validation_data=valid_image_gen,validation_steps=len(valid_image_gen),callbacks=my_checkpointer,verbose=1)